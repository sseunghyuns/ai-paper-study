**Vision Transformers implementation using PyTorch**

</br>

- Trained CIFAR10(32x32)

- Patch size: 4 (A total of 64 patches are made)

- Embedding dimension(D): 128

- Number of heads: 8

- Number of layers: 12

- Number of MLP hidden dimension: 64

---

### Generate images-patches(sample)

- width, height = 512, 384
- patch size = 32
- A total of 192(16*12) patch inputs are generated.
