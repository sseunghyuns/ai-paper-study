## 논문 리스트

### Transformers
- [1] Attention Is All You Need | [논문](https://arxiv.org/abs/1706.03762), [설명](#1), 구현 | 
- [2] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale | [논문](https://arxiv.org/abs/2010.11929), 설명, 구현 |
- [3] How Do Vision Transformers Work? | [논문](https://arxiv.org/abs/2202.06709), 설명, 구현 | 
- [4] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | [논문](https://arxiv.org/abs/2103.14030), 설명, 구현 |
- [5] Formal Algorithms for Transformers | [논문](https://arxiv.org/abs/2207.09238), 설명, 구현 |

---

## Quick paper reviews

### #1
### Attention Is All You Need

<img width="500" alt="1" src="https://user-images.githubusercontent.com/63924704/174219244-bd41642d-5388-43f6-a120-7ab86e21880c.png">

#### Encoder & Decoder
<p align="center">
<img width="1200" alt="2" src="https://user-images.githubusercontent.com/63924704/174219290-99da2a45-8a3a-47c5-9fb4-61e9ac8e72df.png">
</p>

#### Details
<p align="center">
<img width="1200" alt="3" src="https://user-images.githubusercontent.com/63924704/174219322-76fcc5fe-03fe-427d-8b11-f302dd399c9e.png">
</p>

---
